-> nltk: natural language toolkit.
-> What is tokenization?
	Turning a string or document into tokens (smaller chunks)
	One step in preparing a text for NLP
	Many different theories and rules
	You can create your own rules using regular expressions

-> Why tokenize?
	Easier to map part of speech
	Matching common words
	Removing unwanted tokens
